{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "## data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "## models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "## ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# import catboost as cb\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "## model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "## model evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Volumes/Backup Plus/Documents/Data Science/Projects/fannieMae_project/processed_data/Fannie_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "OrInterestRate        0\n",
       "OrUnpaidPrinc         0\n",
       "OrLoanTerm            0\n",
       "OrLTV                 0\n",
       "OrCLTV                0\n",
       "NumBorrowers          0\n",
       "DTIRat                0\n",
       "CreditScore           0\n",
       "NumUnits              0\n",
       "MortInsPerc           0\n",
       "CoCreditScore         0\n",
       "MortInsType           0\n",
       "Default               0\n",
       "Channel               0\n",
       "SellerName            0\n",
       "FTHomeBuyer           0\n",
       "LoanPurpose           0\n",
       "PropertyType          0\n",
       "OccType               0\n",
       "PropertyState         0\n",
       "ProductType           0\n",
       "RelocationMortgage    0\n",
       "Zip                   0\n",
       "first_payment_year    0\n",
       "loan_year             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016885376097890665"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Default\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3194421 entries, 0 to 3194420\n",
      "Data columns (total 26 columns):\n",
      "Unnamed: 0            int64\n",
      "OrInterestRate        float64\n",
      "OrUnpaidPrinc         int64\n",
      "OrLoanTerm            int64\n",
      "OrLTV                 float64\n",
      "OrCLTV                float64\n",
      "NumBorrowers          float64\n",
      "DTIRat                float64\n",
      "CreditScore           float64\n",
      "NumUnits              int64\n",
      "MortInsPerc           float64\n",
      "CoCreditScore         float64\n",
      "MortInsType           float64\n",
      "Default               int64\n",
      "Channel               object\n",
      "SellerName            object\n",
      "FTHomeBuyer           object\n",
      "LoanPurpose           object\n",
      "PropertyType          object\n",
      "OccType               object\n",
      "PropertyState         object\n",
      "ProductType           object\n",
      "RelocationMortgage    object\n",
      "Zip                   int64\n",
      "first_payment_year    int64\n",
      "loan_year             int64\n",
      "dtypes: float64(9), int64(8), object(9)\n",
      "memory usage: 633.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.loc[df['loan_year']==2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92340, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3194421, 179)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd_new.get_dummies(df, drop_first=True)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names first\n",
    "names = df_new.columns\n",
    "# Create the Scaler object\n",
    "scaler = StandardScaler()\n",
    "# Fit your data on the scaler object\n",
    "scaled_df = scaler.fit_transform(df_new)\n",
    "scaled_df = pd.DataFrame(df_new, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scaled_df['Default'].values\n",
    "X = scaled_df.drop(['Default'], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred=dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_score_knn=accuracy_score(y_test, knn_pred)\n",
    "a_score_dt=accuracy_score(y_test, dt_pred)\n",
    "a_score_lr=accuracy_score(y_test, lr_pred)\n",
    "\n",
    "# Print the accuracy scores\n",
    "print(a_score_knn)\n",
    "print(a_score_dt)\n",
    "print(a_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score:\n",
    "The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "\n",
    "$$ F1 = 2 * \\frac{precision * recall}{precision + recall} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "score_knn = f1_score(y_test, knn_pred)\n",
    "score_dt = f1_score(y_test, dt_pred)\n",
    "score_lr = f1_score(y_test, lr_pred)\n",
    "\n",
    "# Print the f1 scores\n",
    "print(score_knn)\n",
    "print(score_dt)\n",
    "print(score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heterogeneous ensemble \n",
    "* wisedom of the crowd\n",
    "* use fine-tuned models\n",
    "* small amount of estimators\n",
    "* **voting and average**\n",
    "\n",
    "### 1) voting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate the individual models\n",
    "\n",
    "knn = KNeighborsClassifier(5)\n",
    "dt = DecisionTreeClassifier()\n",
    "lr = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "\n",
    "# Create and fit the voting classifier\n",
    "clf_vote = VotingClassifier(\n",
    "    estimators=[('knn', knn), ('dt', dt), ('lr', lr)]\n",
    ")\n",
    "clf_vote.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions using the voting classifier\n",
    "pred_vote = clf_vote.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score of the voting classifier\n",
    "score_vote = accuracy_score(y_test, pred_vote)\n",
    "print('voting accuracy-Score: {:}'.format(score_vote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) averaging (soft voting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate the individual models\n",
    "\n",
    "knn = KNeighborsClassifier(5)\n",
    "rf = DecisionTreeClassifier()\n",
    "lr = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "\n",
    "# Create and fit the voting classifier\n",
    "clf_avg = VotingClassifier(\n",
    "    estimators=[('knn', knn), ('dt', dt), ('lr', lr)],\n",
    "    voting='soft',\n",
    "    weights=[2, 1, 1]\n",
    ")\n",
    "\n",
    "\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions using the voting classifier\n",
    "pred_avg = clf_avg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "acc_avg = accuracy_score(y_test,  pred_avg)\n",
    "print('averaging accuracy: {:}'.format(acc_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homogeneous ensemble\n",
    "\n",
    "* use the small model (weak model) \n",
    "* large amount of estimators\n",
    "* **bagging and boosting**\n",
    "* **random forest** is a special case of bagging\n",
    "\n",
    "Condorcet's jury theorm:\n",
    "1) models are independent\n",
    "2) models are slightly better than random guess\n",
    "3) all individual models have similar performance\n",
    "\n",
    "weak model satisfies 2) and 3), bagging algorithm trains individual models using a random subsample for each which guarantee 1). Bootsraping guarantees some of the characteristics of the crowd. Wisedom of the crowd needs to be divers, through using either different algorithms or datasets.\n",
    "\n",
    "Boostrapping requires:\n",
    "* random subsamples\n",
    "* using replacement\n",
    "\n",
    "Boostrapping guarantees:\n",
    "* diverse crowd (different datasets)\n",
    "* indepenent (separately sampled)\n",
    "\n",
    "### why bagging?\n",
    "pro: \n",
    "* bagging usually reduce variance\n",
    "* Overfitting can be avoided by the ensemble itself\n",
    "\n",
    "con:\n",
    "* computational expensive: time and space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Instantiate the base model\n",
    "clf_dt = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Build and train the Bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  base_estimator=clf_dt,\n",
    "  n_estimators=21,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "pred = clf_bag.predict(X_test)\n",
    "\n",
    "# Show the accuracy score\n",
    "print('decision tree bagging accuracy score: {:}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred=rf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "print('randomforest accuracy: {:}'.format(accuracy_score(y_test, rf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a balanced logistic regression\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Build and fit a bagging classifier\n",
    "clf_bag = BaggingClassifier(base_estimator=clf_lr, max_features=10, oob_score=True, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set and show the out-of-bag score\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('logistic classifier accuracy:  {:}'.format(accuracy_score(y_test, pred)))\n",
    "print('OOB-Score: {:}'.format(clf_bag.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## booster\n",
    "gradual learning\n",
    "* iterating learning\n",
    "* dependent estimators\n",
    "* learning different tasks for the same goal\n",
    "* sequential building\n",
    "\n",
    "Possible steps in gradual learning:\n",
    "1. First attempt (initial model)\n",
    "2. Feedback (model evaluation)\n",
    "3. Correct errors (subsequent model)\n",
    "\n",
    "\n",
    "### Adaptive boosting\n",
    "\n",
    "Instances are drawn using a sample distribution\n",
    "* Difcult instances have higher weights\n",
    "* Initialized to be uniform\n",
    "\n",
    "Estimators are combined with a weighted\n",
    "* majority voting\n",
    "* Good estimators are given higher weights\n",
    "\n",
    "Guaranteed to improve\n",
    "\n",
    "Classication and Regression\n",
    "\n",
    "* base_estimator Default: Decision Tree (max_depth=1)\n",
    "* n_estimators Default: 50\n",
    "* learning_rate Default: 1.0\n",
    "* loss default linear (can be change to square or exponential)\n",
    "* Trade-off between n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit a tree-based AdaBoost classifier\n",
    "reg_ada = AdaBoostClassifier(n_estimators=12, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "print('Adaptive boosting classifier accuracy:  {:}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting\n",
    "\n",
    "Objective: $$y=f(X) $$\n",
    "1. Initial model (weak estimator): $y = f_{1}(X)$\n",
    "2. New model ts to residuals: $y - f_{1}(X) = f_{2}(X)$\n",
    "3. New additive model: $y = f_{1}(X) + f_{2}(X)$\n",
    "4. Repeat n times or until error is small enough\n",
    "5. Final additive model: $y = f_{1}(X) + f_{2}(X)... + f_{n}(X) = \\Sigma_{1}^{n}f_{X}(X)$\n",
    "\n",
    "**Equivalence to gradient descent**\n",
    "Residual: $$y-f_{i}(X)$$\n",
    "\n",
    "Gradient Descent:\n",
    "$$ loss = \\frac{(f_{i}(X)-y)^2}{2}$$\n",
    "\n",
    "$$gradient = \\frac{\\partial loss}{\\partial f_i} = f_{i}(X)-y$$\n",
    "\n",
    "Residuals = Negative Gradient:\n",
    "$$y-f_{i}(X) = - \\frac{\\partial loss}{\\partial f_i(X)}$$\n",
    "\n",
    "\n",
    "* n_estimators Default: 100\n",
    "* learning_rate Default: 0.1\n",
    "* max_depth Default: 3\n",
    "* min_samples_split\n",
    "* min_samples_leaf\n",
    "* max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit a Gradient Boosting classifier\n",
    "clf_gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=500)\n",
    "clf_gbm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_gbm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance based on the accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy: {:}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variations of gradient boosting\n",
    "* Extreme Gradient Boosting: XGBoost\n",
    "* Light Gradient Boosting Machine: LightGBM\n",
    "* Categorical Boosting: CatBoost\n",
    "\n",
    "\n",
    "### Extreme Gradient Boosting\n",
    "* Optimized for distributed computing\n",
    "* Paralleltraining by nature\n",
    "* Scalable, portable, and accurate\n",
    "\n",
    "### Light Gradient Boosting Machine\n",
    "* Released by Microsoft (2017)\n",
    "* Faster training and more efcient\n",
    "* Lighter in terms of space\n",
    "* Optimized for parallel and GPU processing\n",
    "* Useful for problems with big datasets and constraints of speed or memory\n",
    "\n",
    "### Categorical Boosting\n",
    "* Open sourced by Yandex (April 2017)\n",
    "* Built-in handling of categorical features\n",
    "* Accurate and robust\n",
    "* Fast and scalable\n",
    "* User-friendly API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier(max_depth=2, objective=\"reg:logistic\")\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance based on the accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy: {:}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking\n",
    "* alike relay race\n",
    "\n",
    "Very similar to the voting and averaging methods where the whole dataset is used by each model to make prediction, except instead of simply voting or averaging as the combiner to get the final prediction, stacking has a second layer of model which has all the predictions as the input features in addition to the original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlxtend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first-layer models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=15, random_state=500)\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Create the second-layer model (meta-model)\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# Create and fit the stacked model\n",
    "clf_stack = StackingClassifier(classifiers=[clf_knn, clf_dt, clf_nb], meta_classifier=clf_lr)\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacked model’s performance\n",
    "print(\"Accuracy: {:}\".format(accuracy_score(y_test, clf_stack.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=500)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(clf_gbm, X_train, y_train, scoring=\"accuracy\", cv=3)\n",
    "\n",
    "# Print avg. accuracy\n",
    "print(\"3-fold accuracy:\", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation and parameter tuning with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbm = GradientBoostingClassifier(random_state=500)\n",
    "\n",
    "# Create the parameter grid\n",
    "gbm_param_grid = {\n",
    "    'clf_gbm__learning_rate': np.arange(0.05, 1, 0.05),\n",
    "    'clf_gbm__n_estimators': np.arange(50, 200, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform RandomizedSearchCV\n",
    "randomized_acc = RandomizedSearchCV(estimator=clf_gbm,param_distributions=gbm_param_grid, n_iter=2, scoring=\"accuracy\", cv=2,verbose=1)\n",
    "\n",
    "# Fit the estimator\n",
    "randomized_acc.fit(X_train,y_train)\n",
    "\n",
    "# Compute metrics\n",
    "print(randomized_acc.best_score_)\n",
    "print(randomized_acc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = randomized_acc.predict(X_test)\n",
    "# Evaluate the performance based on the accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy: {:}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
